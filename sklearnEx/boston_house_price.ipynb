{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruEqbUOJD8NB"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TEEVRwaypVrb"
   },
   "outputs": [],
   "source": [
    "# 수치계산\n",
    "import numpy as np\n",
    "# 자료읽기\n",
    "import pandas as pd\n",
    "\n",
    "# 사이킷런에서 데이터를 읽기위해 datasets import\n",
    "from sklearn import datasets\n",
    "\n",
    "#\n",
    "from sklearn import model_selection\n",
    "#\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/home/ubuntu/anaconda3/envs/OPENCV4/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWq8_WKWpaqx",
    "outputId": "fa563923-a41a-43a5-c7ab-8f2da0790219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "print(x_data.shape) #(506, 13)\n",
    "print(y_data.shape) #(506,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MP_3cmR3D0pU",
    "outputId": "1dfa0ea7-b66e-418f-e987-47e9185b1c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796432012670811\n",
      "0.6263446540831377\n"
     ]
    }
   ],
   "source": [
    "# sklearn은 기본적으로 fit 함수를 사용하여 훈련 데이터 셋에서 모델을 생성합니다. \n",
    "# 그리고 score 함수를 사용해서 생성된 모델의 성능을 확인하고 predict 함수로 테스트 셋의 예측값을 생성합니다. \n",
    "# 이 세가지 함수는 알고리즘의 종류와 관계 없이 대부분의 알고리즘에 존재합니다\n",
    "\n",
    "\n",
    "## x_data = dataset.data, y_data = dataset.target\n",
    "\n",
    "\n",
    "# x_data, y_data 를 약 0.3 비율로 나눠 x_train, x_test, y_train, y_test 에 나눠 넣겠다\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)\n",
    "\n",
    "# LinearRegression class 변수에 넣어주기 \n",
    "estimator = LinearRegression()\n",
    "# 위에서 나눈 x_train, y_train을 LinearRegression.fit 넣어주기 ( 결측치 확인작업? )\n",
    "estimator.fit(x_train, y_train) \n",
    "\n",
    "y_predict = estimator.predict(x_train) \n",
    "score = metrics.r2_score(y_train, y_predict)\n",
    "print(score) #1.0\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "print(score) #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIxS_TCBEDqv",
    "outputId": "b110884f-27aa-4802-cade-e2fe9bff41b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7318528516128472\n",
      "0.406624880386811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "#print(x_data.shape) #(506, 13)\n",
    "#print(y_data.shape) #(506,)\n",
    "\n",
    "####################\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)\n",
    "\n",
    "estimator = KNeighborsRegressor(n_neighbors=5, metric='minkowski', weights='uniform')\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "\n",
    "y_predict = estimator.predict(x_train) \n",
    "score = metrics.r2_score(y_train, y_predict)\n",
    "print(score) #1.0\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "print(score) #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "Df9PbRzlEI4v",
    "outputId": "283beacb-6df2-4a77-ff96-02ec0dff2e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
      "0       0.000752       0.00007  ...        0.521293                1\n",
      "\n",
      "[1 rows x 14 columns]\n",
      "-0.3805458677224257\n",
      "{'n_neighbors': 3}\n",
      "0.7868514704495158\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
      "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
      "  4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
      "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
      "  9.1400e+00]]\n",
      "[22.1 24.3]\n",
      "24.0 22.099999999999998\n",
      "21.6 24.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n1.079732927822041 1.0035082883285351\\n1.0755241796602246 1.0035082883285351\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "#print(x_data.shape) #(506, 13)\n",
    "#print(y_data.shape) #(506,)\n",
    "\n",
    "####################\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)\n",
    "x_train, x_test, y_train, y_test = x_data, x_data, y_data, y_data\n",
    "\n",
    "estimator = KNeighborsRegressor()\n",
    "\n",
    "#'''\n",
    "param_grid = {'n_neighbors':[3]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='r2') #디폴트로 cv=3, 회귀에서 디폴트로 scoring='r2'\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(pd.DataFrame(grid.cv_results_).sort_values(by='param_n_neighbors'))\n",
    "#print(pd.DataFrame(grid.cv_results_).sort_values(by='param_n_neighbors', ascending=0))\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "#'''\n",
    "'''\n",
    "param_grid = {'n_neighbors':[5,1,2,3,4], 'metric':['minkowski','manhattan','euclidean'], 'weights':['uniform','distance']}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score'))\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "'''\n",
    "\n",
    "####################\n",
    "\n",
    "#'''\n",
    "estimator = grid.best_estimator_\n",
    "#'''\n",
    "'''\n",
    "#estimator = KNeighborsRegressor(**grid.best_params_)\n",
    "estimator = KNeighborsRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "'''\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "#score = estimator.score(x_test, y_test)\n",
    "#score = grid.score(x_test, y_test)\n",
    "print(score) #1.0\n",
    "\n",
    "print(x_test[:2])\n",
    "'''\n",
    "[[0.31062919 0.76910373]\n",
    " [0.41938502 0.65613916]]\n",
    "'''\n",
    "y_predict = estimator.predict(x_test[:2])\n",
    "print(y_predict) #[1.00350829 1.00350829]\n",
    "for y1, y2 in zip(y_test, y_predict):\n",
    "    print(y1, y2)\n",
    "'''\n",
    "1.079732927822041 1.0035082883285351\n",
    "1.0755241796602246 1.0035082883285351\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvrorioiETlr",
    "outputId": "90029af5-8797-42ee-925d-0255cf61293d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703017800043073\n",
      "0.6434987343949339\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "#print(x_data.shape) #(506, 13)\n",
    "#print(y_data.shape) #(506,)\n",
    "\n",
    "####################\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)\n",
    "\n",
    "estimator = Lasso(alpha=1.0)\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "\n",
    "y_predict = estimator.predict(x_train) \n",
    "score = metrics.r2_score(y_train, y_predict)\n",
    "print(score) #1.0\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "print(score) #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlNX4MqMy7WY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "#print(x_data.shape) #(506, 13)\n",
    "#print(y_data.shape) #(506,)\n",
    "#df=pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df=pd.DataFrame(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "6whi39ac0MHH",
    "outputId": "252141b5-9f6a-47bf-a11f-ebda1620d8f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "..    ...\n",
       "501  22.4\n",
       "502  20.6\n",
       "503  23.9\n",
       "504  22.0\n",
       "505  11.9\n",
       "\n",
       "[506 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiWAFDgO0tN_"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98i-Rptr0vfQ",
    "outputId": "259ae328-f2ce-4bab-8a08-9ca91380a561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(354,)\n",
      "(152, 13)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgfuLlahEbhZ",
    "outputId": "92e8fcd1-6ad3-45bc-915d-8816510c66b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6687084162221777\n",
      "0.5907946124874918\n"
     ]
    }
   ],
   "source": [
    "estimator = KNeighborsRegressor(n_neighbors=5, metric='minkowski', weights='uniform')\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "\n",
    "y_predict = estimator.predict(x_train) \n",
    "score = metrics.r2_score(y_train, y_predict)\n",
    "print(score) #1.0\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "print(score) #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "36z0oBdMrvji",
    "outputId": "aa08b3a4-3226-49bd-c864-c13d069eea1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
      "0       0.000722       0.00005  ...        0.521293                1\n",
      "\n",
      "[1 rows x 14 columns]\n",
      "-0.3805458677224257\n",
      "{'n_neighbors': 3}\n",
      "0.7868514704495158\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
      "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
      "  4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
      "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
      "  9.1400e+00]]\n",
      "[22.1 24.3]\n",
      "24.0 22.099999999999998\n",
      "21.6 24.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n1.079732927822041 1.0035082883285351\\n1.0755241796602246 1.0035082883285351\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()\n",
    "x_data = dataset.data\n",
    "y_data = dataset.target\n",
    "#print(x_data.shape) #(506, 13)\n",
    "#print(y_data.shape) #(506,)\n",
    "\n",
    "####################\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3)\n",
    "x_train, x_test, y_train, y_test = x_data, x_data, y_data, y_data\n",
    "\n",
    "estimator = KNeighborsRegressor()\n",
    "\n",
    "#'''\n",
    "param_grid = {'n_neighbors':[3]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='r2') #디폴트로 cv=3, 회귀에서 디폴트로 scoring='r2'\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(pd.DataFrame(grid.cv_results_).sort_values(by='param_n_neighbors'))\n",
    "#print(pd.DataFrame(grid.cv_results_).sort_values(by='param_n_neighbors', ascending=0))\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "#'''\n",
    "'''\n",
    "param_grid = {'n_neighbors':[5,1,2,3,4], 'metric':['minkowski','manhattan','euclidean'], 'weights':['uniform','distance']}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score'))\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "'''\n",
    "\n",
    "####################\n",
    "\n",
    "#'''\n",
    "estimator = grid.best_estimator_\n",
    "#'''\n",
    "'''\n",
    "#estimator = KNeighborsRegressor(**grid.best_params_)\n",
    "estimator = KNeighborsRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "'''\n",
    "\n",
    "y_predict = estimator.predict(x_test) \n",
    "score = metrics.r2_score(y_test, y_predict)\n",
    "#score = estimator.score(x_test, y_test)\n",
    "#score = grid.score(x_test, y_test)\n",
    "print(score) #1.0\n",
    "\n",
    "print(x_test[:2])\n",
    "'''\n",
    "[[0.31062919 0.76910373]\n",
    " [0.41938502 0.65613916]]\n",
    "'''\n",
    "y_predict = estimator.predict(x_test[:2])\n",
    "print(y_predict) #[1.00350829 1.00350829]\n",
    "for y1, y2 in zip(y_test, y_predict):\n",
    "    print(y1, y2)\n",
    "'''\n",
    "1.079732927822041 1.0035082883285351\n",
    "1.0755241796602246 1.0035082883285351\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DxLo4Djr451",
    "outputId": "a0d83447-17f5-455a-db2e-0917350785f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "dataset = datasets.fetch_california_housing()\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bznUWSDsBZmB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "boston_house_price.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
